{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression** is a statistical technique in machine learning (Supervised ML) that helps predict continuous values by finding correlations between independent and dependent variables. e.g., house prices, market trends, weather patterns, and oil and gas prices.\n",
    "\n",
    "The goal of a regression algorithm is to plot a best-fit line or curve between the data. The trained model can then be used to predict the target for new data points.\n",
    "\n",
    "**Terminologies Related to Regression Analysis:**\n",
    "1. Response Variable: The primary factor to predict or understand in regression, also known as the dependent variable or target variable.\n",
    "2. Predictor Variable: Factors influencing the response variable, used to predict its values; also called independent variables.\n",
    "3. Outliers: Observations with significantly low or high values compared to others, potentially impacting results and best avoided.\n",
    "4. Multicollinearity: High correlation among independent variables, which can complicate the ranking of influential variables.\n",
    "5. Underfitting and Overfitting: Overfitting occurs when an algorithm performs well on training but poorly on testing, while underfitting indicates poor performance on both datasets.\n",
    "\n",
    "**Regression Types**\n",
    "\n",
    "**1. Simple Regression** - Used to predict a continuous dependent variable based on a single independent variable.\n",
    "**2. Multiple Regression** - Used to predict a continuous dependent variable based on multiple independent variables.\n",
    "**3. NonLinear Regression** - Relationship between the dependent variable and independent variable(s) follows a nonlinear pattern.\n",
    "\n",
    "**Regression Algorithms**\n",
    "\n",
    "**1. Linear Regression**\n",
    "- Linear regression is one of the simplest and most widely used statistical models.\n",
    "- This means that the change in the dependent variable is proportional to the change in the independent variables.\n",
    "\n",
    "**2. Polynomial Regression**\n",
    "- Polynomial regression is used to model nonlinear relationships between the dependent variable and the independent variables. \n",
    "- It adds polynomial terms to the linear regression model to capture more complex relationships.\n",
    "\n",
    "**3. Support Vector Regression (SVR)**\n",
    "- SVM is a type of algorithm that is used for classification tasks, but it can also be used for regression tasks. \n",
    "- SVR works by finding a hyperplane that minimizes the sum of the squared residuals between the predicted and actual values.\n",
    "\n",
    "**4. Decision Tree Regression**\n",
    "- Decision tree regression is a type of regression algorithm that builds a decision tree to predict the target value. \n",
    "- A decision tree is a tree-like structure that consists of nodes and branches. Each node represents a decision, and each branch represents the outcome of that decision. \n",
    "- The goal of decision tree regression is to build a tree that can accurately predict the target value for new data points.\n",
    "\n",
    "**5. Random Forest Regression**\n",
    "- Random forest regression is an ensemble method that combines multiple decision trees to predict the target value. \n",
    "- Ensemble methods are a type of machine learning algorithm that combines multiple models to improve the performance of the overall model. \n",
    "- Random forest regression works by building a large number of decision trees, each of which is trained on a different subset of the training data. \n",
    "- The final prediction is made by averaging the predictions of all of the trees.\n",
    "\n",
    "\n",
    "**Regularized Linear Regression Techniques** (Prevent overfitting)\n",
    "Overfitting occurs when the model learns the training data too well and is unable to generalize to new data.\n",
    "\n",
    "1. Ridge Regression\n",
    "2. Lasso regression - It does this by adding a penalty term to the loss function that forces the model to use some weights and to set others to zero.\n",
    "\n",
    "**Characteristics of Regression**\n",
    "\n",
    "1. Continuous Target Variable: \n",
    "- Regression deals with predicting continuous target variables that represent numerical values. \n",
    "- Examples include predicting house prices, forecasting sales figures, or estimating patient recovery times.\n",
    "\n",
    "2. Error Measurement: \n",
    "- Regression models are evaluated based on their ability to minimize the error between the predicted and actual values of the target variable. \n",
    "- Common error metrics include mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE).\n",
    "\n",
    "3. Model Complexity: \n",
    "- Regression models range from simple linear models to more complex nonlinear models. \n",
    "- The choice of model complexity depends on the complexity of the relationship between the input features and the target variable.\n",
    "\n",
    "4. Overfitting and Underfitting: Regression models are susceptible to overfitting and underfitting.\n",
    "\n",
    "5. Interpretability: Simple linear models are highly interpretable, while more complex models may be more difficult to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
