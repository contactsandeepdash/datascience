{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating your chatbot into your Flask server\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from flask import request\n",
    "import json\n",
    "\n",
    "from flask import Flask\n",
    "from flask_cors import CORS\t\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return 'Hello, World!'\n",
    "\n",
    "@app.route('/bananas')\n",
    "def bananas():\n",
    "    return 'This page has bananas!'\n",
    "    \n",
    "@app.route('/bread')\n",
    "def bread():\n",
    "    return 'This page has bread!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'message'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'prompt': 'message'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/chatbot', methods=['POST'])\n",
    "def handle_prompt():\n",
    "    # Read prompt from HTTP request body\n",
    "    data = request.get_data(as_text=True)\n",
    "    data = json.loads(data)\n",
    "    input_text = data['prompt']\n",
    "\n",
    "    # Create conversation history string\n",
    "    history = \"\\n\".join(conversation_history)\n",
    "\n",
    "    # Tokenize the input text and history\n",
    "    inputs = tokenizer.encode_plus(history, input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the response from the model\n",
    "    outputs = model.generate(**inputs, max_length= 60)  # max_length will acuse model to crash at some point as history grows\n",
    "\n",
    "    # Decode the response\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Add interaction to conversation history\n",
    "    conversation_history.append(input_text)\n",
    "    conversation_history.append(response)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [27/Aug/2024 15:12:17] \"GET /chatbot HTTP/1.1\" 405 -\n",
      "127.0.0.1 - - [27/Aug/2024 15:12:47] \"POST /chatbot HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
